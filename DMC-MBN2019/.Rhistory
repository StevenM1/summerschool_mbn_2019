pp[[1]]
names(pp[[1]])
assign.pp
pp[[1]]
h.log.posterior.dmc(ps,pp,
pp=list(p.mu,p.sigma),
ppp=list(mu.prior,sigma.prior))
rm(list=ls())
source ("dmc/dmc.R")
load_model ("LNR","lnrPP.R")
load_data ("dmc_4_2.RData")
# For example, for the first subject at the true parameters, the likelihood is
sum(log(likelihood.dmc(ps[1,],data.model[[1]])))
# and the corresponding prior is
sum(log.prior.dmc(ps[1,],p.prior))
# The prior summed over population parameters (here the true values) is
sum(log.prior.dmc(p.mu,mu.prior)) + sum(log.prior.dmc(p.sigma,sigma.prior))
# Which sum to:
h.log.posterior.dmc(ps,pp,
pp=list(p.mu,p.sigma),
ppp=list(mu.prior,sigma.prior))
h.log.posterior.dmc
tmp <- h.log.likelihood.dmc(ps=ps,pp=pp=list(p.mu,p.sigma),p.prior=p.prior)
tmp <- h.log.likelihood.dmc(ps=ps,pp=list(p.mu,p.sigma),p.prior=p.prior)
tmp
# This is calculated for each subject, the relevant value is the one
# summed over subjects
sum(tmp)
# The prior summed over population parameters (here the true values) is
sum(log.prior.dmc(p.mu,mu.prior)) + sum(log.prior.dmc(p.sigma,sigma.prior))
# Which sum to:
h.log.posterior.dmc(ps,pp,
pp=list(p.mu,p.sigma),
ppp=list(mu.prior,sigma.prior))
# In the h.log.posterior function the parameter values in pp have no
# influence; they are replaced by the values in pp, but pp still needs to
# be passed to the function to act as a container for the values in pp.
# For example:
p1=rep(NA,5); names(p1) <- names(attr(model,"p.vector"))
h.log.posterior.dmc
h.log.posterior.dmc(ps,p.prior,
pp=list(p.mu,p.sigma),
ppp=list(mu.prior,sigma.prior))
h.log.posterior.dmc(ps,p.prior,
pp=list(p.mu,p.sigma),
pp.prior=list(mu.prior,sigma.prior))
77.01608-4.660229
p1=rep(NA,5); names(p1) <- names(attr(model,"p.vector"))
na.prior <- prior.p.dmc(p1,p2=rep(NA,5))
h.log.posterior.dmc(ps,pp=na.prior,
pp=list(p.mu,p.sigma),
ppp=list(mu.prior,sigma.prior))
p1=rep(NA,5); names(p1) <- names(attr(model,"p.vector"))
na.prior <- prior.p.dmc(p1,p2=rep(NA,5))
h.log.posterior.dmc(ps,pp=na.prior,
pp=list(p.mu,p.sigma),
pp.prior=list(mu.prior,sigma.prior))
h.log.posterior.dmc
h.log.posterior.dmc(ps,p.prior=na.prior,
pp=list(p.mu,p.sigma),
pp.prior=list(mu.prior,sigma.prior))
h.log.posterior.dmc(ps,p.prior,
pp=list(p.mu,p.sigma),
pp.prior=list(mu.prior,sigma.prior))
# In the h.log.posterior function the parameter values in p.prior have no
# influence; they are replaced by the values in pp, but pp still needs to
# be passed to the function to act as a container for the values in pp.
# For example:
p1=rep(NA,5); names(p1) <- names(attr(model,"p.vector"))
na.prior <- prior.p.dmc(p1,p2=rep(NA,5))
h.log.posterior.dmc(ps,p.prior=na.prior,
pp=list(p.mu,p.sigma),
pp.prior=list(mu.prior,sigma.prior))
h.log.posterior.dmc(ps,p.prior=na.prior,
pp=list(p.mu,p.sigma),
pp.prior=list(mu.prior,sigma.prior))
h.log.posterior.dmc(ps,p.prior=p.prior,
pp=list(p.mu,p.sigma),
pp.prior=list(mu.prior,sigma.prior))
pp=list(p.mu,p.sigma)
pp.prior=list(mu.prior,sigma.prior)
h.log.posterior.dmc
sum(h.log.likelihood.dmc(ps,pp,p.prior))
h.summed.log.prior(pp,pp.prior)
h.summed.log.prior(pp,na.prior)
# In the h.log.posterior function the parameter values in p.prior have no
# influence; they are replaced by the values in pp, but pp still needs to
# be passed to the function to act as a container for the values in pp.
# For example:
p1=rep(NA,5); names(p1) <- names(attr(model,"p.vector"))
na.prior <- prior.p.dmc(p1,p2=rep(NA,5))
h.summed.log.prior(pp,na.prior)
# In the h.log.posterior function the parameter values in p.prior have no
# influence; they are replaced by the values in pp, but pp still needs to
# be passed to the function to act as a container for the values in pp.
# For example:
p1=rep(NA,5); names(p1) <- names(attr(model,"p.vector"))
na.prior <- prior.p.dmc(p1,p2=rep(NA,5))
names(na.prior)
na.prior[[1]]
h.log.posterior.dmc
h.summed.log.prior(pp,pp.prior)
sum(h.log.likelihood.dmc(ps,pp,p.prior))
sum(h.log.likelihood.dmc(ps,pp,na.prior))
h.log.likelihood.dmc
tmp=assign.pp(pp,p.prior)
tmp=assign.pp(pp,na.prior)
tmp=assign.pp(pp,p.prior)
tmp1=assign.pp(pp,na.prior)
tmp[[1]]
tmp1[[1]]
identical(tmp,tmp1)
identical(tmp[[1]],tmp1[[1]])
identical(tmp[[2]],tmp1[[2]])
identical(tmp[[3]],tmp1[[3]])
identical(tmp[[4]],tmp1[[4]])
identical(tmp[[5]],tmp1[[5]])
length(tmp)
tmp[[3]]
tmp1[[3]]
p1=rep(NA,5); names(p1) <- names(attr(model,"p.vector"))
na.prior <- prior.p.dmc(p1,p2=rep(NA,5),lower=c(0,0,NA,NA,NA))
h.log.posterior.dmc(ps,p.prior=na.prior,
pp=list(p.mu,p.sigma),
pp.prior=list(mu.prior,sigma.prior))
p1=rep(NA,5); names(p1) <- names(attr(model,"p.vector"))
na.prior <- prior.p.dmc(p1,p2=rep(NA,5),lower=c(NA,NA,0,0,0))
h.log.posterior.dmc(ps,p.prior=na.prior,
pp=list(p.mu,p.sigma),
pp.prior=list(mu.prior,sigma.prior))
# Here the convenience function "assign.pp" is used to first assign the values
# of pp to pp.
pp <- assign.pp(pp=list(p.mu,p.sigma),p.prior)
# Use large sample of subject parameters to check that the maxima are near the
# true values (i.e, p.mu and p.sigma)
tmp <- h.simulate.dmc(model,pp=pp,ns=1000,n=2)
h.simulate.dmc
# Use large sample of subject parameters to check that the maxima are near the
# true values (i.e, p.mu and p.sigma)
tmp <- h.simulate.dmc(model,ps=ps,ns=1000,n=2)
pp
sigma.prior <- prior.p.dmc(
dists = rep("beta", length(p.prior)),
p1=c(A=1, B.r1=1, B.r2=1,
mean_v.f1.true=1, mean_v.f2.true=1, mean_v.f1.false=1, mean_v.f2.false=1,
sd_v.true = 1, t0=1),p2=rep(1,9)
)
par(mfcol=c(2,5)); for (i in names(sigma.prior)) plot.prior(i,sigma.prior)
rm(list=ls())
# Current working directory must be set to the top-level folder
# containing the dmc and tutorial subfolders
source ("dmc/dmc.R")
load_model ("LBA","lba_B.R")
# load_data ("dmc_4_6_fixed.RData")
# load_data ("dmc_4_6_random.RData")
# 2x2 (Stimulus and factor F) specified in model.dmc call
model <- model.dmc(p.map     = list(A="1",B="R",t0="1",mean_v=c("F","M"),sd_v="M",st0="1"),
match.map = list(M=list(s1=1,s2=2)),
factors=list(S=c("s1","s2"),F=c("f1","f2")),
constants = c(sd_v.false=1,st0=0),
responses = c("r1","r2"),
type="norm")
# Parameter vector names are: ( see attr(,"p.vector") )
# [1] "A"               "B.r1"            "B.r2"            "t0"
# [5] "mean_v.f1.true"  "mean_v.f2.true"  "mean_v.f1.false" "mean_v.f2.false"
# [9] "sd_v.true"
#
# Constants are (see attr(,"constants") ):
# sd_v.false        st0
#          1          0
# Population distribution, rate effect on F
pop.mean <- c(A=.4, B.r1=.6, B.r2=.8,
mean_v.f1.true=1.5, mean_v.f2.true=1, mean_v.f1.false=0, mean_v.f2.false=0,
sd_v.true = .25,  t0=.3)
pop.scale <-c(A=.1, B.r1=.1, B.r2=.1,
mean_v.f1.true=.2, mean_v.f2.true=.2, mean_v.f1.false=.2, mean_v.f2.false=.2,
sd_v.true = .1, t0=.05)
pop.prior <- prior.p.dmc(
dists = rep("tnorm",9),
p1=pop.mean,p2=pop.scale,
lower=c(0,0,0,NA,NA,NA,NA,0,.1),upper=c(NA,NA,NA,NA,NA,NA,NA,NA,1)
)
p.prior <- prior.p.dmc(
dists = rep("tnorm",9),
p1=pop.mean,
p2=pop.scale*5,
lower=c(0,0,0,NA,NA,NA,NA,0,.1),upper=c(NA,NA,NA,NA,NA,NA,NA,NA,NA)
)
sigma.prior <- prior.p.dmc(
dists = rep("beta", length(p.prior)),
p1=c(A=1, B.r1=1, B.r2=1,
mean_v.f1.true=1, mean_v.f2.true=1, mean_v.f1.false=1, mean_v.f2.false=1,
sd_v.true = 1, t0=1),p2=rep(1,9)
)
par(mfcol=c(2,5)); for (i in names(sigma.prior)) plot.prior(i,sigma.prior)
rm(list=ls())
# Current working directory must be set to the top-level folder
# containing the dmc and tutorial subfolders
source ("dmc/dmc.R")
install.packages("mvtnorm") # For Bayes Factors
install.packages("mvtnorm")
install.packages("Matrix") # For Bayes Factors
install.packages("Matrix")
install.packages("Matrix")
install.packages("Matrix")
install.packages("Matrix")
install.packages("Matrix")
install.packages("Matrix")
install.packages("Matrix")
install.packages("Matrix")
install.packages("Matrix")
install.packages("Matrix")
install.packages("Brobdingnag") # For Bayes Factors
install.packages("stringr") # For Bayes Factors
require(parallel) # parallel processing
require(msm)  # For truncated normal priors
require(truncdist) # truncated t etc.
require(coda) # Sampling output analysis
require(loo) # For WAIC and looaic calculation
require(hypergeo) # For population plausible values
require(statmod) # Wald model
require(pracma)  # For gng and stop signal robust integration
require(numDeriv) # Prior transformations
require(vioplot) # Stop signal graphs
require(ggplot2) # For fancy graphs
require("mvtnorm") # For Bayes Factors
require("Matrix") # For Bayes Factors
require("Brobdingnag") # For Bayes Factors
require("stringr") # For Bayes Factors
temp_wd <- getwd (); setwd(file.path (temp_wd, "dmc"))
source ("file_utils.R")
# Load in all the DMC modules
source ("dmc_model.R")
source ("dmc_sampling.R")
source ("dmc_hierarchical.R")
source ("dmc_plotting.R")
source ("dmc_analysis.R")
extract.data
extract.p.prior
extract.pp.prior
phi.as.mcmc.list.bridge
split.samples
create.post.mcmc.list
getLbounds
getUbounds
insert.constants
transform2Real
invtransform2Real
logJacobian
log.likelihood.bridge
log.posterior.bridge
assign.pp.bridge
h.log.likelihood.bridge
h.log.posterior.bridge
h.unnormalized.posterior
eval.unnormalized.posterior
run.iterative.scheme
core.bridge.sampler.dmc
bridge.sampler.dmc
h.bridge.sampler.dmc
bf.dmc
source ("dmc/bridge_sampling_functions_warp3.R")
source ("bridge_sampling_functions_warp3.R")
setwd(temp_wd)
rm(list=ls())
# Current working directory must be set to the top-level folder
# containing the dmc and tutorial subfolders
source ("dmc/dmc.R")
rm(list=ls())
# Current working directory must be set to the top-level folder
# containing the dmc and tutorial subfolders
source ("dmc/dmc.R")
# (referred to as "full" model) to a restricted version of the model that fixes
# the parameter mean_v.true to the constant 3.55.
# The Bayes factor is given by the ratio of the models' marginal likelihoods.
# In DMC, we can compute the (log) marginal likelihood of a model using Warp-III
# bridge sampling. Once the marginal likelihood has been obtained for both
# models, we can compute the Bayes factor of interest.
# Although in this example we consider nested models, it should be noted that
# Bayes factors can also be used to compare non-nested models. Furthermore,
# DMC allows users to compute Bayes factors for any implemented model, not just
# the LBA.
load_model ("LBA","lba_B.R")
LBAfull <- model.dmc(
p.map = list(A = "1", B = "1", mean_v = "M", sd_v = "1",
t0 = "1", st0 = "1"),
constants = c(st0 = 0, sd_v = 1),
match.map = list(M = list(s1 = 1, s2 = 2)),
factors = list(S = c("s1", "s2")),
responses = c("r1", "r2"),
type = "norm")
# Select parameter values for data generation
pLBAfull  <- c(A = .5, B = 1, mean_v.true = 4, mean_v.false = 3, t0 = .2)
# Generate a data set with 250 trials per stimulus (i.e., a total of 500 trials)
# from the full model.
set.seed(1) # So results reproduceable
data <- simulate.dmc(pLBAfull, LBAfull, n = 250)
# Bind the data and model together ready for sampling
dmLBAfull <- data.model.dmc(data, LBAfull)
p.priorLBAfull <- prior.p.dmc(
p1 = c(A = 1, B = 1, mean_v.true = 2, mean_v.false = 1, t0 = .3),
p2 = c(1, 1, 3, 3, .25), lower = c(0, 0, NA, NA, .1), upper = rep(NA, 5)
)
# Create object to fill with posterior samples for the full model
sLBAfull <- samples.dmc(nmc = 300, p.priorLBAfull, dmLBAfull, thin = 10)
# Obtain posterior samples for the full model
sLBAfull <- RUN.dmc(sLBAfull, cores = 4, use.effectiveSize = FALSE)
# Check convergence
plot.dmc(sLBAfull)
gelman.diag.dmc(sLBAfull)
# We can now compute the (log) marginal likelihood for the full model using
# Warp-III bridge sampling
bridgeLBAfull <- bridge.sampler.dmc(samples = sLBAfull, cores = 4)
save(sLBAfull, bridgeLBAfull,file="dmc_5_7.RData")
save_data(sLBAfull, bridgeLBAfull,file="dmc_5_7.RData")
dir()
LBAres <- model.dmc(
p.map = list(A = "1", B = "1", mean_v = "M", sd_v = "1",
t0 = "1", st0 = "1"),
constants = c(mean_v.true = 3.55, st0 = 0, sd_v = 1),
match.map = list(M = list(s1 = 1, s2 = 2)),
factors = list(S = c("s1", "s2")),
responses = c("r1", "r2"),
type = "norm")
# Bind the data and model together ready for sampling
dmLBAres <- data.model.dmc(data, LBAres)
# Specify priors for the restricted model
p.priorLBAres <- prior.p.dmc(
p1 = c(A = 1, B = 1, mean_v.false = 1, t0 = .3),
p2 = c(1, 1, 3, .25), lower = c(0, 0, NA, .1), upper = rep(NA, 4)
)
# Create object to fill with posterior samples for the restricted model
sLBAres <- samples.dmc(nmc = 300, p.priorLBAres, dmLBAres, thin = 10)
# Obtain posterior samples for the restricted model
sLBAres <- RUN.dmc(sLBAres, cores = 4, use.effectiveSize = FALSE)
# Check convergence
plot.dmc(sLBAres)
gelman.diag.dmc(sLBAres)
# We can now compute the (log) marginal likelihood for the restricted model
# using Warp-III bridge sampling
bridgeLBAres <- bridge.sampler.dmc(samples = sLBAres, cores = 4)
save_data(sLBAfull, bridgeLBAfull,sLBAres,bridgeLBAres,file="dmc_5_7.RData")
# The Bayes factor is given by the ratio of the models' marginal likelihoods.
# In DMC, we can compute the (log) marginal likelihood of a model using Warp-III
# bridge sampling. Once the marginal likelihood has been obtained for both
# models, we can compute the Bayes factor of interest.
# It should be noted that DMC allows users to compute Bayes factors for any
# implemented model, not just the LBA.
load_model ("LBA","lba_B2v.R")
load("~/Downloads/Europe19/DMC-UTas2019/bridgeB.RData")
tmp=load("~/Downloads/Europe19/DMC-UTas2019/bridgeB.RData")
tmp
load("~/Downloads/Europe19/DMC-UTas2019/bridgeV.RData")
tmp=load("~/Downloads/Europe19/DMC-UTas2019/bridgeV.RData")
tmp
save_data(sLBAfull, bridgeLBAfull,sLBAres,bridgeLBAres,
bridgeB,bridgeV,file="dmc_5_7.RData")
# Now we can compute the Bayes factor in favor of the data-generating B-model
bf_B_V <- bf.dmc(bridgeB, bridgeV)
print(bf_B_V)
# In case the Bayes factor is very large or even (numerically) Inf, it may be
# useful to consider the log Bayes factor that can also be obtained using bf.dmc
logbf_B_V <- bf.dmc(bridgeB, bridgeV, log = TRUE)
print(logbf_B_V)
RUN.dmc
save_data(sLBAfull, bridgeLBAfull,sLBAres,bridgeLBAres,
bridgeB,bridgeV,file="dmc_5_7.RData")
# load the posterior samples for the data generating B-model
# WARNING: This object is LARGE, ~ 142MB
load_data("BBl_1.RData")
system.time({
bridgeB <- h.bridge.sampler.dmc(samples = hBBl_1, cores = 3)
})
11914.525/3600
system.time({
bridgeV <- h.bridge.sampler.dmc(samples = hVVl_1, cores = 3)
})
# load the posterior samples for the data generating B-model
# WARNING: This object is LARGE, ~ 142MB
load_data("VVl_1.RData")
system.time({
bridgeV <- h.bridge.sampler.dmc(samples = hVVl_1, cores = 3)
})
load_data("BVl_1.RData")
load_data("BVl_1.RData")
bridgeV <- h.bridge.sampler.dmc(samples = hVVl_1, cores = 3)
bridgeV <- h.bridge.sampler.dmc(samples = hBVl_1, cores = 4)
bridgeV <- h.bridge.sampler.dmc(samples = hBVl_1, cores = 3)
# Now we can compute the Bayes factor in favor of the data-generating B-model
bf_B_V <- bf.dmc(bridgeB, bridgeV)
print(bf_B_V)
# In case the Bayes factor is very large or even (numerically) Inf, it may be
# useful to consider the log Bayes factor that can also be obtained using bf.dmc
logbf_B_V <- bf.dmc(bridgeB, bridgeV, log = TRUE)
print(logbf_B_V)
bridge.sampler.dmc
load_data ("dmc_5_7.RData")
print(bf_full_res)
# Finally, we can compute the Bayes factor in favor of the full model
bf_full_res <- bf.dmc(bridgeLBAfull, bridgeLBAres)
print(bf_full_res)
# In general, it may be easier to interpret Bayes factor values larger than 1
# which can be achieved by re-expressing the Bayes factor in favor of the
# restricted model. Note that the Bayes factor in favor of the full model and
# the Bayes factor in favor of the restricted model convey the same information
# (bf_full_res = 1 / bf_res_full); re-expressing the Bayes factor so that it is
# larger than 1 is simply a matter of convenience.
bf_res_full <- bf.dmc(bridgeLBAres, bridgeLBAfull)
print(bf_res_full)
1/1.314293
# Now we can compute the Bayes factor in favor of the data-generating B-model
bf_B_V <- bf.dmc(bridgeB, bridgeV)
print(bf_B_V)
# In case the Bayes factor is very large or even (numerically) Inf, it may be
# useful to consider the log Bayes factor that can also be obtained using bf.dmc
logbf_B_V <- bf.dmc(bridgeB, bridgeV, log = TRUE)
print(logbf_B_V)
bridge.sampler.dmc
rm(list=ls())
# Current working directory must be set to the top-level folder
# containing the dmc and tutorial subfolders
source ("dmc/dmc.R")
load_data ("dmc_5_7.RData")
# Finally, we can compute the Bayes factor in favor of the full model
bf_full_res <- bf.dmc(bridgeLBAfull, bridgeLBAres)
print(bf_full_res)
# In general, it may be easier to interpret Bayes factor values larger than 1
# which can be achieved by re-expressing the Bayes factor in favor of the
# restricted model. Note that the Bayes factor in favor of the full model and
# the Bayes factor in favor of the restricted model convey the same information
# (bf_full_res = 1 / bf_res_full); re-expressing the Bayes factor so that it is
# larger than 1 is simply a matter of convenience.
bf_res_full <- bf.dmc(bridgeLBAres, bridgeLBAfull)
print(bf_res_full)
bridgeLBAfull$logml
bridgeLBAres$logml
bridgeLBAres <- bridge.sampler.dmc(samples = sLBAres, cores = 1)
# Current working directory must be set to the top-level folder
# containing the dmc and tutorial subfolders
source ("dmc/dmc.R")
# We will first use the single-participant example from Gronau et al. (2018).
# In this example, we compute a Bayes factor to compare a simple LBA model
# (referred to as "full" model) to a restricted version of the model that fixes
# the parameter mean_v.true to the constant 3.55.
# The Bayes factor is given by the ratio of the models' marginal likelihoods.
# In DMC, we can compute the (log) marginal likelihood of a model using Warp-III
# bridge sampling. Once the marginal likelihood has been obtained for both
# models, we can compute the Bayes factor of interest.
load_model ("LBA","lba_B.R")
bridgeLBAres <- bridge.sampler.dmc(samples = sLBAres, cores = 1)
rm(list=ls())
source("dmc/dmc.R")
install.packages("truncdist") # truncated t etc.
install.packages("msm")  # For truncated normal priors
install.packages("loo") # For WAIC and looaic calculation
install.packages("hypergeo") # For population plausible values
install.packages("statmod") # Wald model
install.packages("rtdists") # For standard model distribution functions
install.packages("pracma")  # For gng and stop signal robust integration
install.packages("snowfall") # Parallel processing
install.packages("msm")
# This modificaiton of coda allows for plotting of priors with plot.dmc
install.packages("packages/coda_0.19-3.tar.gz",repos=NULL,type="source")
install.packages("rtdists") # For standard model distribution functions
install.packages("pracma")  # For gng and stop signal robust integration
install.packages("snowfall") # Parallel processing
install.packages("rlecuyer") # Parallel processing
install.packages("numDeriv") # Prior transformations
install.packages("vioplot") # Stop signal graphs
install.packages("ggplot2") # For fancy graphs
install.packages("mvtnorm") # For Bayes Factors
install.packages("Matrix") # For Bayes Factors
install.packages("Brobdingnag") # For Bayes Factors
install.packages("stringr") # For Bayes Factors
# This modificaiton of coda allows for plotting of priors with plot.dmc
install.packages("packages/coda_0.19-3.tar.gz",repos=NULL,type="source")
## -- Installation Note
install.packages("Matrix")
# This downloads all of the example files.
# NOTE: if a download breaks part way thorugh it
#       leaves a corrupt file and when you try to
#       download again, with the following message
# Error in load(path, envir = .GlobalEnv) :
#       empty (zero-byte) input file
# You will have to delete the offending file from
# \tutorial\data to fix this and start again.
rm(list=ls())
source("dmc/dmc.R")
load_data ("dmc_1_1.RData")
load_data ("dmc_1_2.RData")
load_data("dmc_3_1.RData")
load_data ("dmc_3_2.RData")
load_data ("dmc_3_3.RData")
load_data ("dmc_3_4.RData")
load_data ("dmc_3_5.RData")
load_data ("dmc_4_2.RData")
load_data ("dmc_4_4.RData")
load_data ("dmc_4_5.RData")
load_data ("dmc_4_6_fixed.RData")
load_data ("dmc_4_6_random.RData")
load_data ("dmc_4_7_fixed.RData")
load_data ("dmc_4_7_random.RData")
load_data ("dmc_5_3.RData")
load_data ("dmc_5_4.RData")
load_data("dmc_5_5.RData")
load_data("dmc_5_6.RData")
load_data("dmc_5_7.RData")
load_data ("dmc_6_1.RData")
load_data ("dmc_6_2.RData")
load_data ("dmc_6_3.RData")
load_data ("dmc_6_4.RData")
load_data ("dmc_6_5.RData")
