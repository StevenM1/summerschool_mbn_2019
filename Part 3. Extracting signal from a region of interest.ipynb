{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3. Extracting signal from a region of interest\n",
    "\n",
    "In Part 1, we preprocessed the data (or, at least, explored *how* you could go about preprocessing your data). Let's just use the `fmriprep`-preprocessed data for the remainder of the tutorial. Here, we will extract signal from a region of interest: striatum. Striatum is part of the Basal Ganglia, and has repeatedly been implicated in response caution adjustments (e.g., [Forstmann et al 2008](http://www.pnas.org/content/105/45/17538/#F2); [Van Maanen et al 2011](http://www.jneurosci.org/content/31/48/17488)). In Part 3 and 4 of this tutorial, we'll see if we can replicate this result.\n",
    "\n",
    "In order to extract signal from a region of interest, we need a mask that tells us where this ROI lies in the brain. Since `fmriprep` registered ('normalized') our data to MNI152-space, we can use a mask from an atlas in MNI152-space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from nipype.interfaces import fsl\n",
    "import nilearn.datasets\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A look at masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the directory `/data/masks/` you can find various masks, including one for the left and one for the right striatum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /data/masks/MNI152-2mm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load a mask and see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_l = nib.load('/data/masks/MNI152-2mm/STR_L.nii.gz').get_data()\n",
    "plt.imshow(str_l[:, 68, :].T, origin='lower', cmap=plt.cm.hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this is a *probabilistic* map. The colors in the above plot indicate the *probability* for each voxel that is is part of any given individual's left striatum. Further, probabilities of 0 lead to a black pixel in the plot above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's mask all voxels that have a probability of 50% or less of belonging to any of the striatal parts. This way, they won't end up as black pixels when we plot them, but become transparant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_l = np.ma.masked_less(str_l, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, `str_l` is a 3D-matrix indicating for each voxel the probability that it belongs to the left striatum. What does this look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(str_l[:, 68, :].T, origin='lower', cmap=plt.cm.hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The background is now white instead of black, which doesn't help much. But now we can superimpose this mask on an MNI152 template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNI template\n",
    "mni = nib.load('/data/mni_icbm152_nlin_asym_09c/2mm_T1.nii.gz').get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.imshow(mni[:, 68, :].T,origin='lower', cmap=plt.cm.gray)\n",
    "plt.imshow(str_l[:, 68, :].T,origin='lower', cmap=plt.cm.hot)\n",
    "plt.grid('off')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.imshow(mni[38, :, :].T,origin='lower', cmap=plt.cm.gray)\n",
    "plt.imshow(str_l[38, :, :].T,origin='lower', cmap=plt.cm.hot)\n",
    "plt.grid('off')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.imshow(mni[:, :, 40].T,origin='lower', cmap=plt.cm.gray)\n",
    "plt.imshow(str_l[:, :, 40].T,origin='lower', cmap=plt.cm.hot)\n",
    "plt.grid('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's where left striatum is located probabilistically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `str_l` variable is a kind of image. You can apply image processing tools to it; for example, to find the center of mass (this is how the slices plotting above were chosen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "from scipy import ndimage\n",
    "com = ndimage.center_of_mass(str_l)\n",
    "com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Can you make the same plots for right striatum? Find the center of mass, and plot it on an MNI152-brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting signal from a masked region\n",
    "Back to Nipype. Nipype contains interfaces that allows you to extract a time series *meaned* over a region of interest. The interface is called `ImageMeants()`. Let's first see how this works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll need these libraries below\n",
    "from nipype.interfaces import fsl\n",
    "import nipype.pipeline.engine as pe\n",
    "import nipype.interfaces.io as nio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /data/deriv/fmriprep/sub-483/func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracter = fsl.ImageMeants()\n",
    "extracter.inputs.in_file = '/data/deriv/fmriprep/sub-483/func/sub-483_task-SAT_run-1_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz'\n",
    "extracter.inputs.mask = '/data/masks/MNI152-epi/STR_L.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = extracter.run()\n",
    "r.outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using `np.loadtxt(<path_to_txt_file>)`, you can load the output. \n",
    "\n",
    "2) Can you plot the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a pipeline\n",
    "Now we semi-manually extracted a single subject's time series signal meaned over striatum. We could do this in the same way for all subjects, but it's much more efficient to make a pipeline. Let's make one that extracts the time series meaned over striatum for all participants. First, set-up the nodes we want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the node that extracts signal\n",
    "extracter = pe.MapNode(fsl.ImageMeants(), iterfield='in_file', name='extract_mean_ts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this is a [MapNode](https://pythonhosted.org/nipype/api/generated/nipype.pipeline.engine.nodes.html#mapnode) rather than a regular Node; i.e., a Node the receives a list of inputs and applies the same interface to each element of the list.\n",
    "\n",
    "3) In the cell below, create/fill: \n",
    "- the template for where to find the masks\n",
    "- the template for where to find the functional data (similar to Part 1)\n",
    "- all subject ids at selector.iterator. \n",
    "- fill in the mask names at selector.iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we set-up a SelectFile-Node\n",
    "templates = {\n",
    "    'mask': '/data/masks/MNI152-epi/ ... ',    # NB: folder \"MNI152-epi\" here is correct - dont use \"MNI152-2mm\"\n",
    "    'func': '/data/deriv/fmriprep/ ... '\n",
    "}\n",
    "\n",
    "selector = pe.Node(nio.SelectFiles(templates=templates), name='file_selector')\n",
    "selector.iterables = [('subject_id', [ ... ]),   # enter subejct ids\n",
    "                      ('mask', [ ... ])] # enter mask names\n",
    "\n",
    "\n",
    "# A datasink is useful for exporting. Remember the base_directory - this is where the data will be saved later\n",
    "ds = pe.Node(nio.DataSink(base_directory='/data/extracted_signals'), \n",
    "             name='datasink')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, combine everything in a Workflow.\n",
    "\n",
    "4) In the cell below, make the right connections in the workflow: you want to connect the `selector` to the `extractor` in two ways. Remember that you can call `fsl.ImageMeants.help()` to see the input argument names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = pe.Workflow(base_dir='/data/workflow_folders/', \n",
    "                       name='extract_striatum_signal')\n",
    "\n",
    "# Connect the Nodes\n",
    "workflow.connect(selector, 'mask', extracter, ...) # complete the connection\n",
    "workflow.connect(selector, 'func', extracter, ...) # complete the connection\n",
    "workflow.connect(extracter, 'out_file', ds, 'extracted_timeseries')\n",
    "\n",
    "# Make a graph to visualize what we did..\n",
    "workflow.write_graph('graph.dot', format='png')\n",
    "from IPython.display import Image\n",
    "Image('/data/workflow_folders/extract_striatum_signal/graph.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we're ready to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.run('MultiProc', plugin_args={'n_proc': 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "5) Again, visualize what the output data structure looks like using `!tree`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
