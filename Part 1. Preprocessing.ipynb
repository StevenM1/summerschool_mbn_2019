{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. Preprocessing fMRI data using `fmriprep` and `Nipype`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will preprocess fMRI data. We will explore two options for preprocessing:\n",
    "1. Using [`fmriprep`](http://fmriprep.readthedocs.io/), a pipeline developed by the Poldrack lab\n",
    "2. Building your own pipeline using [`Nipype`](https://nipype.readthedocs.io/en/latest/)\n",
    "\n",
    "Nipype is a pipelining tool that makes it easy to share pipelines of fMRI preprocessing, as well as document them, and run (them in parallel on a cluster). In fact, `fmriprep` makes use of `Nipype`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import libraries that contain useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nipype                    # Nipype is a pipelining tool\n",
    "import nibabel as nib            # Nibabel is a library to read in nifti-files\n",
    "import numpy as np               # Numpy is 'matlab for Python'\n",
    "import matplotlib.pyplot as plt  # Matplotlib is a plotting library\n",
    "import seaborn as sns            # Seaborn is an extension to matplotlib, that offers \n",
    "                                 # convenience wrappers and nicer looking plots\n",
    "\n",
    "import os                        # Useful for directory specification later on\n",
    "\n",
    "# This (obscure) line of code causes figures to be plotted in line with the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and visualize data\n",
    "First, let's have a look at what the data actually look like. Below, we load the functional data of a single subject and a single run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdr = nib.load('/data/bids/sub-197/func/sub-197_task-SAT_run-1_bold.nii.gz')\n",
    "data = hdr.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now `data` is a numpy-array: a matlab-like matrix, that is efficiently stored in memory, and can be accessed fast using pointers.\n",
    "\n",
    "##### 1. What is the size of this matrix ([hint](http://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.shape.html))?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last dimension is _time_, that is, there are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "volumes in this run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Try to average the data over the time-dimension ([hint](http://docs.scipy.org/doc/numpy/reference/generated/numpy.mean.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `mean_data` variable is now a 3D-matrix containing the mean signal in each voxel. Let's try to visualize this. You can now use the following code to make an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mean_data[:, 40, :,].T, origin='lower', cmap=plt.cm.gray, interpolation='nearest')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an 'coronal' slice. \n",
    "\n",
    "##### 3. Can you edit the code to make an _axial_ slice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also inspect the changes in voxel intensity over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can plot like this\n",
    "plt.plot(data[32, 40, 20, :])\n",
    "plt.title('Voxel intensity over time')\n",
    "plt.xlabel('Volume number')\n",
    "plt.ylabel('Intensity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the image above, you can see a gradual increase in signal over time. This drift is generally removed in preprocessing by applying a high-pass filter\n",
    "\n",
    "##### 4. Calculate the total amount of time between the first and last volumes. Note that the repetition time (time between volumes) is 1.994s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using `fmriprep`\n",
    "`fmriprep` is a package developed by the Poldrack lab to do the minimal of preprocessing required. It covers motion correction, field unwarping, registration, and brain extraction. It uses a combination of well-known software packages (e.g., FSL, SPM, ANTs, AFNI) and selects the 'best' implementation of each preprocessing step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once installed, `fmriprep` can be invoked from the command line. One nice feature of IPython Notebooks (i.e., the thing in your browser you're right now looking at) is that you can invoke command line commands with an `!`, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /data/bids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where `ls` is a command that shows all files and directories in a given directory (here, /data)\n",
    "\n",
    "Since `fmriprep` is run from command line, you can even run it from within a notebook. For example, the following command should work after you remove the 'hashtag' `#`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!fmriprep --output-spaces MNI152NLin2009cAsym --use-syn --fs-license-file=../license.txt /data/bids /data/output_folder participant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command above consists of the following parts:\n",
    "   - \"fmriprep\" calls fmriprep\n",
    "   - --output-spaces --output-spaces MNI152NLin2009cAsym tells fmriprep to normalize (register) data to template MNI152 version 6 (2009c)\n",
    "   - --fs-license-file ../../license.txt tells fmriprep where to find the license.txt-file for freesurfer - you can ignore this\n",
    "   - --fs-no-reconall tells it not to run surface reconstruction\n",
    "   - --use-syn tells it to run SyN susceptibility distortion correction (this is experimental)\n",
    "   - bids is the name of the folder containing the data in bids format\n",
    "   - output_folder is the name of the folder where we want the preprocessed data to be stored\n",
    "   - participant tells fmriprep to run only at the participant level (and not, for example, at the group level - you can forget about this)\n",
    "   \n",
    "The [official documentation](http://fmriprep.readthedocs.io/) contains all possible arguments you can pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running fmriprep takes quite some time (I included the hashtag to prevent you from accidentally running it - you can, of course, but it probably won't finish today). So I did this for you in advance. The results can be found in the path `/data/deriv` (which stands for 'derivates': data derived from the original data). \n",
    "\n",
    "One particularly nice feature of `fmriprep` is that it generates a nice html-file that allows you to easily inspect whether all preprocessing steps went right. For example, to inspect how preprocessing went for `sub-197`, you can click [here](/view/logs/sub-197.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Have a look at the logs of preprocessing subject 197. What happened in each of the steps?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating your own preprocessing pipeline\n",
    "The strength of `fmriprep` is arguably that it makes decisions for you, and makes things easier. However, this is also its weakness: you are dependent on the choices that others have made for you. In many cases, these choices are fine - however, when it comes to analyzing MRI-data, there is no \"one size fits all\". Even Russ Poldrack, as one of the main developers, mentions in his paper Scanning the Horizon (NRN 2017): \"we do not believe that there will be a single\n",
    "best workflow for all studies; in fact, there is direct evidence that different studies or individuals will probably benefit from different workflows\". Different situations require different pipelines, and thus it is useful to be able to create your own preprocessing pipeline.\n",
    "\n",
    "An excellent pipelining tool is `Nipype`. Unfortunately, it has a bit of a steep learning curve. Below, we superficially explore how Nipype works. A complete tutorial into Nipype is beyond the scope of today's workshop, but I hope to give you a quick overview and the right references to find your way.\n",
    "\n",
    "### Nipype: The basics\n",
    "Nipype is a _pipelining_ tool; that is, it allows you to create a pipeline (or workflow) of different steps of processing. Importantly, Nipype does not implement processing algorithms itself; rather, it serves as a wrapper for common algorithms built in FSL, SPM, ANTs, and AFNI. You can also add your own steps if you want, either coded in Python or as a command line call to another software package.\n",
    "\n",
    "So let's make a simple pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Defining what you want to do\n",
    "In the lecture, I mentioned that common preprocessing steps include motion correction (sometimes called 'realigning'), and spatial smoothing. Let's start with these two steps, and use FSL's algorithms to do this:\n",
    "\n",
    "1. MCFLIRT for motion correction, \n",
    "2. IsotropicSmooth for smoothing\n",
    "\n",
    "First, we load these MCFLIRT and IsotropicSmooth `interfaces`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.fsl import MCFLIRT, IsotropicSmooth  # these are called interfaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a _Node_ for each interface, which will allow us to connect these interfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype import Node  # import the Node-class first\n",
    "\n",
    "# wrap each of the interfaces in a Node, and name them.\n",
    "mc = Node(MCFLIRT(dof=6), name='motion_correct')\n",
    "smoother = Node(IsotropicSmooth(fwhm=6), name='smooth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the MCFLIRT-interface received an argument 'dof', which stands for the degrees of freedom in transforming the functional images (here, I used 6: 3 degrees of freedom for rotation, and 3 for translation). Similarly, the IsotropicSmooth was provided a `fwhm` (the amount of smoothing to apply), which is set to 6mm.\n",
    "\n",
    "If you want to know what arguments you should (or can) provide to interfaces, you can call the help()-method of an interface. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCFLIRT.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under `Inputs::`, you can find the mandatory and optional input arguments. Similarly, under `Outputs::`, you can find what MCFLIRT returns (most importantly: `out_file`, which is the motion-corrected time series - but you also get the motion parameters and transformation matrices).\n",
    "\n",
    "So now we initialized two nodes. Next, we can connect the Nodes together in a Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Creating a workflow & connecting the Nodes\n",
    "Two cells above, we defined the individual steps that the workflow needs to do. Here, we connect the steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the 'pipeline engine' from nipype\n",
    "from nipype import Workflow\n",
    "\n",
    "# First, create the workflow object\n",
    "wf = Workflow(name='simple_preprocessing_workflow', \n",
    "              base_dir='/data/workflow_folders')\n",
    "# the base_dir is the directory that is used to store intermediate results. \n",
    "# You want to use /data/workflow_folders on the current server but probably not on your own computer.\n",
    "\n",
    "# wf is now a Workflow, but it currently doesn't do anything yet. \n",
    "\n",
    "# Next, we, connect 2 nodes using the .connect()-method. Suppose we want to connect\n",
    "# Node 1 to Node 2, such that the output of Node 1 (e.g., the motion-corrected image) is used as input for Node 2.\n",
    "# Then we need four arguments:\n",
    "# 1. the name of Node 1 we want to connect\n",
    "# 2. the name of the output of Node 1 we want to connect\n",
    "# 3. the name of Node 2 we want to connect\n",
    "# 4. the name of the input-argument of Node 2\n",
    "\n",
    "# This probably seems abstract, but here is an example:\n",
    "wf.connect(mc, 'out_file', smoother, 'in_file')\n",
    "\n",
    "# The line above connects the 'out_file' provided by mc (recall: the Node that handles motion-correction) \n",
    "# to the 'in_file'-argument of smoother (recall: the node that handles smoothing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(The cell above doesn't give any output - this is normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Providing input & specifying output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to tell the nodes which files to process. Let's use as an example a single functional run from a single subject. This can be found in `/data/bids/sub-197/func/sub-197_task-SAT_run-1_bold.nii.gz`\n",
    "\n",
    "Note that we specify the input arguments for the _nodes_, and not the workflow. You can do this under the `<node>.inputs.<input_name>` attribute, where `<node>` stands for the variable name of the node (e.g., `mc`, `smoother`, as defined earlier), and `<input_name>` for the input name of the field (e.g., `in_file`, as found in the .help()-method of the relevant interface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tell mc (the motion correct node) what input file to process\n",
    "mc.inputs.in_file = '/data/bids/sub-197/func/sub-197_task-SAT_run-1_bold.nii.gz'\n",
    "\n",
    "# Since the output of mc is 'piped'/connected to the input of smoother (we connected these nodes in the previous cell), \n",
    "# we don't need to define the input for smoother anymore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to store the output of the smoother somewhere. By default, the workflow stores all files in the `base_dir` (which also acts as a cache). You can use a DataSink-node to move part of the output to an output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.io import DataSink  # import data sink here\n",
    "\n",
    "# Create a node with the datasink\n",
    "ds = Node(DataSink(base_directory='/data/preprocessed_files'), name='datasink')\n",
    "wf.connect(smoother, 'out_file', ds, 'smoothed_data') \n",
    "\n",
    "# Here, we tell the workflow to make sure that the out_file of the smoother is ported to the DataSink, \n",
    "# which saves it in a folder called \"smoothed_data\"\n",
    "wf.connect(mc, 'out_file', ds, 'motion_corrected_data')  # and let's also save the motion corrected data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A great feature of Nipype is that you can visualize your workflow in a graph. Let's do this to show what we just did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "wf.write_graph(graph2use='colored')\n",
    "Image(os.path.join('/data/workflow_folders/simple_preprocessing_workflow/graph.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's looking plain but simple. Now we're ready to run this workflow!\n",
    "\n",
    "#### Step 4: Running the pipeline, and visualizing results\n",
    "\n",
    "Running a pipeline can be done by calling the `.run()`-method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wf.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the workflow has finished, let's see what happened. \n",
    "\n",
    "We told the DataSink to store everything in this directory: `/data/preprocessed_files`. Using the `tree` in the command line, we can generate a 'directory tree':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree /data/preprocessed_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, so we found the motion corrected data and the smoothed data. First, let's see if the data is actually smoothed. We can do this by comparing the raw data with the output data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, plot a slice of four volumes of the raw data\n",
    "hdr = nib.load('/data/bids/sub-197/func/sub-197_task-SAT_run-1_bold.nii.gz')\n",
    "data = hdr.get_data()\n",
    "f, ax = plt.subplots(nrows=1, ncols=4)\n",
    "ax[0].imshow(data[:,40,:,10].T, origin='lower')\n",
    "ax[1].imshow(data[:,40,:,30].T, origin='lower')\n",
    "ax[2].imshow(data[:,40,:,50].T, origin='lower')\n",
    "ax[3].imshow(data[:,40,:,80].T, origin='lower')\n",
    "f.set_size_inches(h=5, w=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at exactly the same volumes & slices of the output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdr = nib.load('/data/preprocessed_files/smoothed_data/sub-197_task-SAT_run-1_bold_mcf_smooth.nii.gz')\n",
    "data = hdr.get_data()\n",
    "f, ax = plt.subplots(nrows=1, ncols=4)\n",
    "ax[0].imshow(data[:,40,:,10].T, origin='lower')\n",
    "ax[1].imshow(data[:,40,:,30].T, origin='lower')\n",
    "ax[2].imshow(data[:,40,:,50].T, origin='lower')\n",
    "ax[3].imshow(data[:,40,:,80].T, origin='lower')\n",
    "f.set_size_inches(h=5, w=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, smoothing worked! How about the motion correction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdr = nib.load('/data/preprocessed_files/motion_corrected_data/sub-197_task-SAT_run-1_bold_mcf.nii.gz')\n",
    "data = hdr.get_data()\n",
    "f, ax = plt.subplots(nrows=1, ncols=4)\n",
    "ax[0].imshow(data[:,40,:,10].T, origin='lower')\n",
    "ax[1].imshow(data[:,40,:,30].T, origin='lower')\n",
    "ax[2].imshow(data[:,40,:,50].T, origin='lower')\n",
    "ax[3].imshow(data[:,40,:,80].T, origin='lower')\n",
    "f.set_size_inches(h=5, w=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, it doesn't seem obviously _wrong_, but it's hard to see any difference from the raw data. Usually, when you call FSL's MCFLIRT, you can also plot the motion parameters, which help you inspect whether there was any excessive motion. Our pipeline currently doesn't plot these parameters. So let's try to adapt our workflow to have it _also_ plot some motion parameters.\n",
    "\n",
    "#### Extending the simple pipeline to include a motion parameter plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.fsl import PlotMotionParams\n",
    "\n",
    "# Create nodes\n",
    "mc = Node(MCFLIRT(dof=6, save_plots=True), name='motion_correct')  \n",
    "# Note that we now explicitly ask MCFLIRT to save motion parameters by entering `save_plots=True`\n",
    "\n",
    "smoother = Node(IsotropicSmooth(fwhm=6), name='smooth') # same as before\n",
    "motion_plotter = Node(PlotMotionParams(in_source='fsl', plot_type='translations'), name='motion_plot') # this is new!\n",
    "ds = Node(DataSink(base_directory='/data/preprocessed_files_wf2'), name='datasink') # same as before\n",
    "\n",
    "# Create pipeline\n",
    "wf2 = Workflow(name='simple_preprocessing_workflow2', \n",
    "               base_dir='/data/workflow_folders')\n",
    "\n",
    "# Connect nodes\n",
    "wf2.connect(mc, 'out_file', smoother, 'in_file') # this is the same as before\n",
    "wf2.connect(mc, 'out_file', ds, 'motion_corrected_data')  # also the same as before \n",
    "\n",
    "# Here, we pass the motion parameters from mc to the motion parameter plotter\n",
    "wf2.connect(mc, 'par_file', motion_plotter, 'in_file')  \n",
    "wf2.connect(smoother, 'out_file', ds, 'smoothed_data')\n",
    "wf2.connect(motion_plotter, 'out_file', ds, 'motion_plots')\n",
    "# Here, we tell the workflow to make sure that the out_file of the smoother is ported to the DataSink, \n",
    "# which saves it in a folder called \"smoothed_data\"\n",
    "\n",
    "# Tell the motion correction node what the input file is\n",
    "mc.inputs.in_file = '/data/bids/sub-197/func/sub-197_task-SAT_run-1_bold.nii.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the workflow we built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf2.write_graph(graph2use='colored')\n",
    "Image('/data/workflow_folders/simple_preprocessing_workflow2/graph.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good, so let's run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf2.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the command line command `tree`, we can see the output of this pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree /data/preprocessed_files_wf2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can load the image here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('/data/preprocessed_files_wf2/motion_plots/sub-197_task-SAT_run-1_bold_mcf.nii.gz_trans.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional exercises to get the hang of building Workflows\n",
    "Above, the basic concepts of building Nipype workflows were introduced. Now, let's try to see if you can expand the workflow we created before. Try to do the following:\n",
    "\n",
    "1. The `MotionPlotter`-interface in `wf2` only plots translations. Can you extend the workflow to also plot rotations?\n",
    "2. Extend `wf2` to *start* with a SliceTimer() FSL-interface (assume that slices were acquired in interleaved order with a TR of 2)\n",
    "3. Extend `wf2` to *start* with a node that removes the first 5 volumes (you can use the ExtractROI()-interface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-configured pipelines & iterating over subjects\n",
    "You don't always have to do *everything* yourself. Nipype comes with pre-configured preprocessing workflows, developed by the neuroimaging community. (Note that the disadvantages of `fmriprep` also apply here, except that it's maybe easier to adapt one of Nipype's pre-configured pipelines than it is to adapt `fmriprep`)\n",
    "\n",
    "Here, we use a pre-configured FSL preprocessing pipeline. The goal here is mostly to show you that these exist, and use them to illustrate a *very* useful feature: automatically looping over subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.workflows.fmri.fsl import create_featreg_preproc  # here we import a function that creates a workflow\n",
    "import nipype.interfaces.io as nio  # useful\n",
    "\n",
    "# create_featreg_preproc is a function that creates a preprocessing pipeline (or 'workflow') for fmri-data\n",
    "preproc_workflow = create_featreg_preproc()\n",
    "\n",
    "# Nipype workflows require a directory where it can temporary store files (used as a cache). We define this here\n",
    "preproc_workflow.base_dir = '/data/workflow_folders'\n",
    "\n",
    "# Set up smoothing (to 0) and highpass filtering at 64 seconds\n",
    "TR = 1.994\n",
    "preproc_workflow.inputs.inputspec.fwhm = 0.0\n",
    "preproc_workflow.inputs.inputspec.highpass = 64 / TR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the workflow `preproc_workflow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "preproc_workflow.write_graph(graph2use='colored', )\n",
    "Image('/data/workflow_folders/featpreproc/graph.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a bit more complex than we did before. It handles realigning (=motion correction), spatial smoothing, and high-pass filtering (NB: no registration).\n",
    "\n",
    "\n",
    "I'm including this pipeline to illustrate how to easily tell `Nipype` to run this pipeline *for all subjects*. Crucial for this is to understand the _data structure_. Ipython notebook makes it possible to run shell ('linux') commands, like _ls_, that show the contents of a directory.\n",
    "\n",
    "This are the directories that contain the 'raw' fMRI files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree /data/bids/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /data/bids/sub-197"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /data/bids/sub-197/func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to have Nipype automagically loop over these subjects, we have to make a template of what the functional files look like.  Have a look at the documentation for the [SelectFiles-interface](https://nipype.readthedocs.io/en/latest/users/select_files.html)\n",
    "\n",
    "Can you fill in the {subject_id}-variable at the right spots?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # fill in\n",
    "templates = {'func': '/data/bids/ ... task-SAT_run-*_bold.nii.gz'}\n",
    "\n",
    "# Note that you can use the * as a so-called wildcard; that is, it currently selects *all* runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're creating a Node with a SelectFiles-interface. We tell the SelectFiles-interface what the template is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = Node(nio.SelectFiles(templates), name='selector')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We connect this new selector node right to the start of the preproc-workflow. Note that the entrynode of the preproc-workflow was called \"inputspec\". Using `preproc_workflow.get_node(\"inputspec\")`, we can make sure to connect the Selector to this Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_workflow.connect(selector, 'func', preproc_workflow.get_node(\"inputspec\"), 'func')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to tell the selector how to iterate over subjects. In other words: what values should be filled in 'subject_id' as defined in the template?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the first four subject IDs\n",
    "selector.iterables = [('subject_id', ['197', ...])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, like before, let's set-up a datasink to save the high-pass filtered data and mean data to an output filder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Node(nio.DataSink(), name='datasink')\n",
    "ds.inputs.base_directory = '/data/preprocessed_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_workflow.connect(preproc_workflow.get_node(\"outputspec\"), 'highpassed_files', ds, 'highpassed_files')\n",
    "preproc_workflow.connect(preproc_workflow.get_node(\"outputspec\"), 'mean', ds, 'mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can visualize the workflow one more time to see what we just did (compare the start & end of this graph with the previous graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "preproc_workflow.write_graph(graph2use='colored')\n",
    "Image('/data/workflow_folders/featpreproc/graph.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we're ready to run! As a final note, it's very easy to run the pipeline in parallel on multiple processes, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preproc_workflow.run(plugin='MultiProc', plugin_args={'n_procs' : 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you visualize the output using `tree`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Additional resources\n",
    "\n",
    "The above tutorial is meant to give you a taste of how to do pre-processing with Nypipe. An excellent, more in-depth tutorial on how to use Nypipe can be found here:\n",
    "https://miykael.github.io/nipype_tutorial/\n",
    "\n",
    "For the remainder of this tutorial, we will work with data preprocessed using fmriprep"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
